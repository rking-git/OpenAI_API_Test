{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e41a594-9d7c-451c-9edd-53d6902a1735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai #needed for error handling\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df0d3c2b-cab6-4dfa-a7f1-7c3af5199385",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY']  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e165ea-fd84-46db-98a6-8e323d3a7b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "#sets the persona for the AI assistant using a system message\n",
    "context = [{'role':'system', 'content':\"\"\"You are a friendly AI assistant that \n",
    "                                              helps compose professional-sounding tweets \n",
    "                                              for Twitter that often go viral based on a \n",
    "                                              website I provide. You will provide a summary \n",
    "                                              of the website in 30 words or less.\"\"\"\n",
    "            }]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ef8242-bb70-4eb0-9246-db0c50cecca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each interaction with the AI assistant is a new session so the entire chat/message history, \n",
    "# including user prompts and assistant responses must be included in each exchange with the\n",
    "# model/assistant so that it \"remembers\"\n",
    "\n",
    "#This is called Prompt Chaining\n",
    "\n",
    "def collect_messages(role, message): #keeps track of the message exchange between user and assistant\n",
    "    context.append({'role': role, 'content':f\"{message}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a5d6744-aab2-4d4a-a5a5-f4bfb2634503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sends the prompts to the model for a completion/response\n",
    "\n",
    "def get_completion(temperature=0): \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=context, \n",
    "            temperature=temperature, \n",
    "        )\n",
    "\n",
    "        print(\"\\n Assistant: \", response.choices[0].message.content, \"\\n\")\n",
    "        return response.choices[0].message.content\n",
    "    except openai.APIError as e:\n",
    "        print(e.http_status)\n",
    "        print(e.error)\n",
    "        return e.error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ad4371-e46c-4bf6-bf7d-b54192656f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the conversation between the user and the AI assistant/chatbot\n",
    "    \n",
    "while True:\n",
    "    collect_messages('assistant', get_completion()) #stores the response from the AI assistant\n",
    "    \n",
    "    user_prompt = input('User: ') #input box for entering prompt\n",
    "    \n",
    "    if user_prompt == 'exit': #end the conversation with the AI assistant\n",
    "        print(\"\\n Goodbye\")\n",
    "        break\n",
    "\n",
    "    collect_messages('user', user_prompt) #stores the user prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
